Run this on a google collab terminal, make sure a GPU based runtime is used.

Hardware
SM : Streaming Multiprocessor, consisting of many physical cores

Programming
nvcc : NVIDIA Cuda Compiler
Warp Size : The smallest number of threads that are scheduled together on an NVIDIA GPU (usually 32)
Block : All threads in a block has access to __shared__ memory. Blocks are scheduled in unit of warps.
Grid : Composed on multiple blocks
Kernel : A piece of code that executes on a GPU __global__. Does not return values.
  Few input parameters are implicit threadIdx.x,y,z; blockIdx.x,y,z; blockDim.x,y,z; gridDim.x,y
  When invoking a kernel, use <<<numBlocks, threadsPerBlock>>>kernel_function()
  https://github.com/Infatoshi/cuda-course/blob/master/05_Writing_your_First_Kernels/01%20CUDA%20Basics/01_idxing.cu
  launch: kernel_name<<<gridDim, blockDim, Ns, Stream>>>()
  Ns : Number of bytes to allocate for block level shared memory
  Stream : Operations launched using the same stream will be sequential.
    This enables parallel launching of different operations, use stream to sequence dependent operations.

Performance
Warp Size - blocks not being a multiple of Warp Size wastes cores
Shared Memory - all threads in a block has access to shared memory which is faster than VRAM memory
Barriers/wait -
  cudaDeviceSynchronize() wait for all device operations to complete
  cudaStreamSynchronize(stream) wait for device operation of the given stream to complete
  __syncthreads wait for all threads in a block (call made from within the kernel)
  __syncwarps wait for all threads in a warp (call made from within the kernel)

Calling functions from within a kernel:
Only call functions that are executable inside a GPU. These are __device__ functions (check the header files).
Some functions are declared as __host__ __device__ these are capable of being executed on host or device.
https://docs.nvidia.com/cuda/cuda-math-api/index.html

Profiling:
https://youtu.be/86FAWCzIe_4?t=11934
1) Install https://developer.nvidia.com/nsight-systems
  On GPU host : wget https://developer.nvidia.com/downloads/assets/tools/secure/nsight-systems/2025_1/NsightSystems-linux-public-2025.1.1.103-3542797.run
  On Mac : profile viewer https://developer.nvidia.com/nsight-systems/get-started
2) Instrument code
  #include <nvtx3/nvToolsExt.h>
  nvtxRangePush("Start X");
    nvtxRangePush("Start Y");
    nvtxRangePop();
  nvtxRangePop();
3) Comple and execute kernel on host with GPU
  nvcc -o profile profile.cu -lnvToolsExt
  nsys profile --stats=true -o profile ./app
  nsys stats --report cuda-api-summary --format csv -o profile.csv profile.nsys-rep

Reference
https://github.com/Infatoshi/cuda-course/tree/master/05_Writing_your_First_Kernels/01%20CUDA%20Basics
