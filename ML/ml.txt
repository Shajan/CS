m: Number of training samples
x: Input Features
n: Number of features
y: Output
(x(i), y(i)): i-th element in training set

Hypothesis
	h: Hypothesis; Maps x to y

	A linear function of x
	h-theta(x) = theta-0 + theta-1 * x1 + theta-2 * x2...
	Set x0 == 1
	h(x) = Sum(i=0 to n) theta-i * x-i
	Vectorization
		h-theta(x) = transpose(theta) * x

Cost Function
	Find theta that minimizes error : Sum(1 to m training set) (h-theta(x) - y)^2
	J(theta) = {Sum(i:1..m)[(h-theta(x-i) - y-i)^2]}/(2m)
	Find theta so that J(theta) is minimized

To find a local minima
	Find the slope of J at the point J(theta), then follow the slope down
	Keep doing this till the slope is horizontal
	Slope is the derivative of J(theta) wrt. theta
		NOTE: slope of f(x) = x^2 is 2x [derivative of f(x) wrt. x]
	Partial derviatives of J(theta) = {Sum(i:1..m)[(h-theta(x-i) - y-i)^2]}/(2m)
		=  Sum(i:1..m)[2*(h-theta(x-i) - y-i)]/(2m)
		=  Sum(i:1..m){(h-theta(x-i) - y-i)}/m

Gradient Descent
	Algorithm for minimizing a function by repeatedly updating thetas (constants)
	Start from a random place
	Take one step in the downward direction in each step
	Converges to a local minimum
	theta-j <= theta-j - Alpha*(partialDerivative of J(theta) wrt theta-j)
		Note: partialDerivative of J(theta) wrt. theta is the slope of J(theta)
	Alpha : Learning rate, too large can cause jumping back and forth
	Update all values of theta simultaniously in each step
	Slope gets more horizontal as we approach minimum, which causes step to become smaller

	
	J(theta) = {Sum(i:1..m)[(h-theta(x-i) - y-i)^2]}/(2m)
	Partial derivative of J(theta) wrt theta = [sum(i:1..m)(h-theta(x-i) - y-i)*x-i]/m

Linear Regression using Gradient Descent
	Repeat {
		theta-j <= theta-j - alpha * [sum(i:1..m)(h-theta(x-i) - y-i)*x-i]/m
			perform update of all thetas (theta-0, theta-1...) in one step
        }
	Gradient descent for linear regression has only one global minimum - based on J(theta) is defined.

Vectorized Linear Regression

	alpha: learning rate (number)
	labels : x[row:1..m;col:0..n], y[row:1..m]
	weights : theta[row:0..n]
		Initial value random, converges to trained value (vector)

	(1..n)
	  theta[row:i] = theta[row:i] - (alpha/m)*delta[row:i]          // Update theta for each iteration
		theta = theta - (alpha/m) * (x*theta' - y)' * x
	  (1..m)
	    delta[row:i] = sum(j:1..m) { error[row:j] } x[col:i]        // Sum over training set, error*feature (vector[1..n])
		(x*theta' - y)' * x
	    error[row:j] = hypothesis[row:j] - y[row:j]                 // Error for label 'j' hypotheis - result (vector[1..m])
		((x[row:j,]*theta') - y[row:j])
	    hypothesis[row:j] = x[row:j,*] * transpose(theta[*])        // Hypothesis using theta[0..n] for features x[0..n] (vector[1..m])
		(x[row:j,]*theta')

